\documentclass[pdftex,12pt,a4paper]{article}

\usepackage[pdftex]{graphicx}
\usepackage{url}
\usepackage{verbatim}

\usepackage{xspace}
\newcommand{\CEU}{\textsc{C\'{e}u}\xspace}
\newcommand{\GVT}{\textsc{LuaGravity}\xspace}
\newcommand{\code}[1] {{\small{\texttt{#1}}}}

\usepackage{color}
    \definecolor{light}{gray}{0.92}
    \definecolor{dark}{gray}{0.30}
    %\definecolor{light}{rgb}{.90,.90,.90}
    \definecolor{darkgreen}{rgb}{0,.50,0}
    \definecolor{darkblue}{rgb}{0,0,.50}
    \definecolor{darkred}{rgb}{.50,0,0}
    \definecolor{darkpur}{rgb}{.50,0,.50}

\usepackage{listings}
%\usepackage{textcomp}
\lstset{
%columns=fullflexible,
%basicstyle=\ttfamily,
escapeinside={||},
mathescape=true,
    language=C, % choose the language of the code
    basicstyle=\fontfamily{pcr}\selectfont\scriptsize\color{black},
    keywordstyle=\color{black}\bfseries, % style for keywords
    numbers=none, % where to put the line-numbers
    numberstyle=\tiny, % the size of the fonts that are used for the line-numbers
    backgroundcolor=\color{light},
    showspaces=false, % show spaces adding particular underscores
    showstringspaces=false, % underline spaces within strings
    showtabs=false, % show tabs within strings adding particular underscores
    %frame=single, % adds a frame around the code
    tabsize=2, % sets default tabsize to 2 spaces
    %rulesepcolor=\color{gray}
    captionpos=t, % sets the caption-position to bottom
    breaklines=false, % sets automatic line breaking
    %breakatwhitespace=false,
    numbersep=2em,
    emph={par,or,hor,do,end,loop,await,emit,input,every,event,call,with,command,%
          var,and,then,else,C,return,pure,deterministic,nohold,finalize,%
          each, abort, when, signal, FOREVER, class, spawn, native, 
    safe,container,async},
    emphstyle={\bfseries},
    commentstyle=\color{dark}\scriptsize,
    %xleftmargin=20pt,
    %xrightmargin=20pt,
    framesep=20pt,
    %upquote=true,
    %aboveskip={1.5\baselineskip},
}

%\renewcommand{\chaptername}{}
%\renewcommand{\thesection}{}
%\setcounter{chapter}{-1}

\begin{document}

\begin{titlepage}
\begin{center}

\textsc{\LARGE PUC--Rio}\\[1.5cm]
\textsc{\Large Research Plan}\\[0.8cm]

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\HRule \\[0.4cm]
{ \huge \bfseries Synchronous Languages for
                  General Purpose Reactive Systems }\\[0.4cm]
\HRule \\[1.5cm]

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Autor:}\\
Francisco Sant'Anna
\end{flushleft}
\end{minipage}
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Advisors:} \\
Roberto Ierusalimschy \\
Noemi Rodriguez
\end{flushright}
\end{minipage}

\vfill
{\large \today}
\end{center}
\end{titlepage}

\tableofcontents

\newpage
\section{Abstract}

The proposed research plan, entitled ``Synchronous Languages for General 
Purpose Reactive Systems'', aims to expand the use of static and 
safety-oriented synchronous languages to embrace general purpose reactive 
systems, such as GUIs, games, multimedia, and networked applications.

Synchronous languages typically target critical embedded systems, relying on a 
restricted semantics to enable static analysis in programs and provide a number 
of compile-time safety guarantees.
%
On the one hand, synchronous programs are predictable in terms of memory usage, 
execution time, and behavior.
%
On the other hand, they are limited in expressiveness, restricting support for 
dynamic memory allocation and for describing algorithmic-intensive 
computations.
%
Although these limitations are not impeditive in the context of embedded 
systems, they are unacceptable for general purpose reactive programming.

Our goal is to study how to tune the safety and expressiveness boundaries of
synchronous languages in a way that reactive applications can benefit of 
powerful mechanisms, while retaining as much efficiency and safety guarantees 
as possible.

\section{Introduction}

Concurrent languages can be generically classified in two major execution 
models.
%
In the \emph{asynchronous model}, the program activities (e.g. threads and 
processes) run independently of one another as result of non-deterministic 
preemptive scheduling.
In order to coordinate at specific points, these activities require explicit 
use of synchronization primitives (e.g. mutual exclusion and message passing).
%
In the \emph{synchronous model}, the program activities (e.g. callbacks and 
coroutines) require explicit control/scheduling primitives (e.g. returning or 
yielding).
For this reason, they are inherently synchronized, as the programmer himself 
specifies how they execute and transfer control.

Due to the simpler and disciplined execution model, synchronous languages are 
susceptible to static analysis and verification, being an established 
alternative to $C$ in the field of safety-critical embedded 
systems~\cite{rp.twelve}.
%
However, in order to enable static analysis, synchronous programs typically 
suffer from two main limitations in expressiveness:
\emph{lack of safe dynamic memory allocation support} and
\emph{impossibility of doing algorithmic-intensive computations}.
%
Memory allocation makes the static prediction about memory usage more 
difficult, transferring the burden of memory management to runtime and to 
programmers, which makes programs less safe.
It also requires programmers to handle pointers explicitly, raising a number of 
safety threats, such as \emph{dangling pointers} and \emph{memory leaks}.
%Furthermore, it affects the performance of programs, given that memory 
%allocation algorithms have some (possibly unpredictable) runtime overhead.
%Finally, heap usage may affect the stack and vice-versa, leading to hard-
%specially considering MMU-less embedded platforms
%
%* mem pools
%
Algorithm-intensive computations (e.g., compression, image processing) break 
the synchronous execution hypothesis, as control transfer among activities now 
happens in an unbounded amount of processing time~\cite{rp.hypothesis}.
%
For reactive applications, instantaneous feedback is fundamental, and minimal 
delays in responsiveness may affect the system correctness.

\CEU~\cite{ceu.tr,ceu.phd,ceu.sensys13,ceu.rem13}
and
\GVT~\cite{luagravity.sblp,luagravity.msc}
are two synchronous languages with distinct goals that we have been developing 
during the past 6 years.

\CEU is a Esterel-based~\cite{esterel.ieee91} reactive language that targets 
constrained embedded platforms, such as Arduino%
\footnote{\url{http://www.arduino.cc}}
and wireless sensor nodes (e.g. \emph{micaz}%
\footnote{\url{http://www.xbow.com}}).
It is designed from scratch and pursues safety and efficiency, targeting highly 
constrained embedded systems.
Most of the complexity of the language resides on the static analysis that 
happens at compile time.
The compiler forbids unbounded loops and verifies that no two accesses to the 
same variable occur at the same time.
It also calculates exact upper limits for memory usage, concurrent lines of 
execution, and nested invocations of internal events.
Therefore, there are no runtime errors regarding memory allocations, race 
conditions, and unbounded execution.

\GVT provides runtime extensions to the programming language Lua~\cite{lua.pil} 
for a better support for building reactive applications.
\GVT supports the emerging functional reactive programming style (FRP) for 
building declarative GUIs~\cite{frp.flapjax,frp.elm,frp.survey}.
Being an extension module, instead of a new language on its own, \GVT inherits 
all functionality of Lua, with unrestricted support for loops, recursive calls, 
and heap-allocated tables, closures, and coroutines.
Therefore, \GVT pursues power and flexibility, relying on a dynamic language 
that already pushes most safety checks to runtime.

Overall, \CEU produces more tractable and reliable programs, but also rapidly 
hits a limit in expressiveness when used outside its restricted embedded 
domain.
%
Our goal with this research plan is to push the expressiveness limits of \CEU 
towards general purpose reactive systems.
%
Starting from \CEU's restricted and tractable semantics, we can keep the 
precise memory and execution model that allows the compiler to predict resource 
usage.
%
In contrast, most FRP systems expose turing-complete functional languages to 
programmers, and hence, cannot provide static safety guarantees.

\section{Research plan}

Our goal is to extend the expressiveness of the programming language \CEU, 
while accommodating two conflicting requirements:

\begin{itemize}
    \item Keep the safety and resource efficiency of synchronous languages.
    \item Overcome the two main limitations of synchronous languages:
            \emph{dynamic memory allocation}
            and
            \emph{performing algorithmic-intensive computations}.
\end{itemize}

\CEU was designed for constrained embedded systems, and we do not want to 
abdicate of its small footprint and compile-time safety guarantees.
%
In order to overcome the limitations in expressiveness and embrace 
general-purpose reactive systems, we plan to add new functionality keeping the 
safety mindset of the language:

\begin{itemize}
    \item For dynamic allocation, we want to employ the use of memory pools 
    under the hoods for predicting memory usage at compile time and enforcing
    deterministic behavior for memory management.
    We also want to take advantage of \CEU's high level compositions to limit 
    the visibility of allocated objects and reclaim memory efficiently through 
(static) lexical analysis.
    \item For algorithmic-intensive computations we plan to add an asynchronous 
primitive that cannot share memory with the reactive/synchronous code.
    With this approach, the reactive part of the program remains with the 
static guarantees, while the asynchronous execution has no restrictions, but 
cannot interfere with the synchronous execution.
\end{itemize}

After introducing \CEU, we provide more details regarding the two proposals 
above and present possible application scenarios to evaluate the results.

\subsection{The programming language C\'eu}

\begin{figure}[t]
\begin{lstlisting}[numbers=left,xleftmargin=3em]
par do
    loop do
        await 250ms;
        _led_toggle(0);
    end
with
    loop do
        await 500ms;
        _led_toggle(1);
    end
with
    loop do
        await 1000ms;
        _led_toggle(2);
    end
end
\end{lstlisting}
\rule{13.8cm}{0.37pt}
\caption{
    An introductory example in \CEU that blinks three LEDs (identified as 0, 1, 
    and 2) in parallel trails.
    The LEDs blink every $250ms$, $500ms$, and $1000ms$, respectively.
    \label{lst.blink}
}
\end{figure}

\CEU~\cite{ceu.sensys13,ceu.phd,ceu.rem13,ceu.tr} is a synchronous reactive 
language that supports multiple lines of execution---known as 
\emph{trails}---that continuously react to external input events broadcast by 
the environment.
%
The example in Figure~\ref{lst.blink} blinks three LEDs in parallel with 
different frequencies.

By following the synchronous model, each trail in \CEU reacts to an occurring 
event with a \emph{run-to-completion} policy: the scheduler of \CEU is 
non-preemptive and deterministic.
%
Reactions to subsequent events never overlap, and the compiler ensures that 
programs do not contain \emph{unbounded loops} (i.e., loops without 
\code{await} statements) which could lead to unresponsiveness for incoming 
events.
%
%Note in the example of Figure~\ref{lst.blink} that every second the three 
%trails awake at the same time, but the deterministic scheduler follows the 
%order they appear in the code (i.e., first \emph{LED 0} toggles, then 
%\emph{LED 1}, and then \emph{LED 2}).

Programs in \CEU are structured with standard imperative primitives, such as 
sequences, loops, and assignments.
The extra support for parallelism allows programs to wait for multiple events 
at the same time.
Trails await events without loosing context information, such as locals and the 
program counter, which eases reasoning in concurrent 
applications~\cite{sync_async.cooperative}.
%
The conjunction of parallelism with standard control-flow enable hierarchical 
compositions, in which self-contained blocks of code can be deployed 
independently.
%
To illustrate the power of compositions in \CEU, consider the two variations of 
the structure that follows:

\begin{minipage}[t]{0.35\linewidth}
\begin{lstlisting}
loop do
    par/and do
        <...>
    with
        await 1s;
    end
end
\end{lstlisting}
\end{minipage}
%
\hspace{1cm}
%
\begin{minipage}[t]{0.35\linewidth}
\begin{lstlisting}
loop do
    par/or do
        <...>
    with
        await 1s;
    end
end
\end{lstlisting}
\end{minipage}

In the \code{par/and} loop variation, the code in the first trail (represented 
as \code{...}) is repeated every second at minimum, as the second trail must 
also terminate to rejoin the \code{par/and} primitive and restart the loop.
%
In the \code{par/or} loop variation, if the code does not terminate within a 
second, the second trail rejoins the composition (cancelling the first trail) 
and restarts the loop.
%
The two structures represent, respectively, the \emph{sampling} and 
\emph{timeout} patterns, which are common in embedded applications.
%
Note that the body of \textbf{\code{<...>}} may contain arbitrary code with 
nested compositions and awaits, but the described patterns will work as 
expected.

The conjunction of parallel compositions with the disciplined synchronous 
execution model provides precise information about the control flow of 
applications, such as which lines of executions can be active, and which 
variables are accessed in reaction to a specific event.
%
As a summary, the following safety properties hold for all programs that 
successfully compile in \CEU~\cite{ceu.sensys13}:
%
\begin{itemize}
\item Time-bounded reactions to the environment.
\item No concurrency in accesses to shared variables.
\item No concurrency in system calls sharing a resource.
\item Synchronization for timers in parallel.
\end{itemize}

\subsection{Dynamic memory allocation}

Dynamic memory is a fundamental mechanism in general-purpose programming, 
allowing programs to accommodate short-lived objects without keeping them in 
memory for the whole execution.

\CEU has no special support for memory allocation, relying on standard 
\emph{malloc} \& \emph{free} from $C$.
%
However, standard memory management raises a number of challenges to the design 
of safe applications:

\begin{enumerate}
\item \textbf{Run-time overhead:}
    Memory management requires extra run-time bookkeeping for the 
    allocation/reclamation algorithms.
    In real-time reactive applications, such as video games, even a small delay 
    may be noticed by the user.
\item \textbf{Unreproducible execution:}
    Successive executions of the same program may allocate memory in different 
    ways, possibly leading to different outcomes (e.g. an allocation fail).
\item \textbf{Reclamation hazards:}
    Properly reclaiming memory is far from trivial.
    A missed reclamation leads to a memory leak that wastes memory, while 
    reclaiming a memory block still in use leads to a dangling pointer that 
will eventually crash the application.
\end{enumerate}

A common alternative in the context of embedded systems is to use \emph{memory 
pools} as the underlying scheme to manage dynamic allocation.
A memory pool is a static buffer of \emph{N} predefined fixed-sized blocks of 
memory that can be used by an application.
%
With memory pools two of the threats raised above can be eliminated:

\begin{enumerate}
\item
The run-time overhead is minimal because implementations typically use simple 
arrays to hold the memory blocks: allocation and reclamation are \emph{O(1)}.
\item
Given that memory operations are simple and only handle fixed-size blocks, the 
execution is always deterministic and predictable.
\item
Memory pools are still manipulated through explicit allocation/reclamation 
operations.
Hence, all challenges to properly reclaim memory still hold.
\end{enumerate}

Regarding reclamation hazards, a typical alternative is to employ automatic 
memory management relying on a garbage collector.
%
However, garbage collection increases the complexity of the language and also 
incurs a considerable runtime overhead.

\begin{figure}[t]
\begin{lstlisting}[numbers=left,xleftmargin=3em]
par/or do
    container do
        // Self-contained block of code that uses
        // dynamic allocation.
        <...>
            ref = alloc(<...>);
        <...>
    end
with
    <...>
end
\end{lstlisting}
\rule{13.8cm}{0.37pt}
\caption{
    All memory allocated inside the \code{container} block is automatically 
    reclaimed after it goes out of scope.
    \label{lst.container}
}
\end{figure}

The support for compositions and self-contained blocks of code in \CEU opens an 
opportunity for an alternative approach that is efficient and avoids explicit 
memory reclamation by the programmer.
%
In the example of Figure~\ref{lst.container}, the hypothetical \code{container} 
keyword (line 2) encloses a block of code that allocates dynamic memory (lines 
3-7).
When the container goes out of scope (suppose the block in line 10 terminates), 
all memory allocated inside it can be automatically reclaimed.
It is important that references to allocated blocks do not escape the 
container, what requires a trivial lexical analysis at compile time.

\subsection{Algorithmic-intensive computations}

Applications often need to perform some kind of heavy computation, such as 
compressing a file, or converting an image format.
It is important that while the computation executes, the application does not 
``freeze'' and remains reactive to external events.
%
However, the synchronous execution model relies on the hypothesis that 
computations run infinitely faster than the rate of external events, which is 
not valid when facing heavy computations.

\begin{figure}[t]
\begin{lstlisting}[numbers=left,xleftmargin=3em]
par/or do
    <...> // defines ret, p1, p2
    ret = async (p1, p2) do
              <...>     // heavy computation
              return v;
          end
with
    <...>
end
\end{lstlisting}
\rule{13.8cm}{0.37pt}
\caption{
    An \code{async} block executes independently (``detached'') from the 
    synchronous part of the program.
    \label{lst.async}
}
\end{figure}

We agree on the fact that heavy computations are fundamentally incompatible 
with the synchronous model and propose the addition of an \emph{asynchronous} 
primitive to \CEU.
Such primitive has already being adopted by other synchronous 
systems~\cite{esterel.primer,frp.elm}.
%
Figure~\ref{lst.async} illustrates how an asynchronous execution can be started 
from the program.
The \code{async} block (lines 3-6) may contain arbitrary code with heavy 
computations (line 4).
On startup, the program may pass parameters by copy to the \code{async} (e.g.  
\code{p1} and \code{p2} in line 3).
On termination, the \code{async} may return a value to the program 
(\code{return} in line 5 to the assignment in line 3).
%
While the trail that spawned the \code{async} waits for its termination, other 
parts of the program in parallel (line 8) remain reactive.

An explicit boundary between synchronous and asynchronous execution make their 
uses clear and brings the benefits of both worlds:

\begin{description}
\item[Synchronous]
    Safe and deterministic execution;
    Support for shared-memory concurrency;
    No need for extra synchronization primitives (e.g. \emph{mutexes});
    Reactive behavior with highest priority.

\item[Asynchronous]
    Non-deterministic execution;
    Share nothing concurrency;
    Parallelizable in multi cores;
    Background computations with lower priority.
\end{description}

\subsection{Application scenarios}

In order to evaluate the applicability of synchronous languages to 
general-purpose reactive systems, we intend to develop real applications in the
scenarios that follow:

\begin{description}
    \item [Games.]
    Video games push the limits of reactive systems, requiring real time 
    responsivenes for user input.
    Games also have plenty of heavy computations that allow us to explore 
    asynchronous execution, such as collision detection and path finding 
algorithms.

    \item [Multimedia.]
    Multimedia applications have a high degree of spatio and temporal 
    synchronization among objects.
    There are plans to port Ginga~\cite{ncl} (the Brazilian middleware for 
    Digital TV) to a pure synchronous implementation~\cite{ncl.sync}.

    \item [Network.]
    Networked applications introduce an unreliable component in applications, 
    which have to deal with communication delays and failures.
    We have already done a few experiments in \CEU with undergraduate students 
    in classes of distributed systems.
\end{description}

By developing applications in the described scenarios, we can also evaluate our 
design through quantitative metrics, as follows:

\begin{description}
    \item [CPU usage.]
    Both proposals of extensions to \CEU can be evaluated through CPU usage:
    performance of automatic memory management and
    parallelization of asynchronous blocks of code.
    \item [Source code size.]
    Even though source code size is not the ultimate metrics for code 
    complexity, it provides straightforward means to compare different 
implementations for the same application.
\end{description}

\section{Conclusion}

General-purpose reactive systems can benefit from the efficiency and safety 
guarantees of synchronous languages.
%
However, synchronous languages suffer from two main limitations:

\begin{itemize}
    \item Lack of safe dynamic memory allocation support.
    \item Impossibility of doing algorithmic-intensive computations.
\end{itemize}

In this research plan, we proposed concrete directions to address these 
limitations:

\begin{itemize}
    \item Employ the use of memory pools to predict memory usage and enforce 
    deterministic behavior.
    Limit the scope of objects for automatic and efficient reclaiming of 
    memory.
    \item Introduce a ``share nothing'' asynchronous primitive with no 
    restrictions regarding heavy computations.
\end{itemize}
 
\begin{comment}

\section{Researchers}

\begin{description}

\item[PUC--Rio (proponent):]
\hspace{1mm}

\textbf{Francisco Sant'Anna} is a third year Ph.D. student in the Computer 
Science department at PUC-Rio. He earned his BSc (2003) and MSc (2007) degrees 
also in the Computer Science department at PUC-Rio.

The current title of his PhD thesis is ``: Embedded, Safe, and Reactive 
Programming'', which is expected to be concluded in September 2013.
His advisors are Prof. Roberto Ierusalimschy and Prof. Noemi Rodriguez, which 
actuate, respectively, in the field of programming languages and distributed 
systems.

\textbf{Prof. Roberto Ierusalimschy} is an associate professor of informatics 
at PUC-Rio (Pontifical University in Rio de Janeiro).
He is the leading architect of the Lua programming language and the author of 
Programming in Lua.\cite{lua.pil}

His research activities currently focus on programming languages, mainly 
alternative languages such as scripting languages and domain-specific 
languages.

\textbf{Prof. Noemi Rodriguez} is an associate professor of informatics at 
PUC--Rio.
Her research interests include the area of concurrent and distributed 
programming, with an emphasis on the role of programming languages in this 
context.
She also leads the Wireless Sensor Networks research group at PUC--Rio.

\item[Chalmers University (host):]
\hspace{1mm}

\textbf{Prof. Philippas Tsigas} is a professor in the Department of Computing 
Science and Engineering at Chalmers University.
He is the co-leader of the Distributed Computing and Systems Research Group.
His research interests center on distributed/parallel computing and systems and 
information visualization in general.

Homepage:
\url{http://www.cse.chalmers.se/~tsigas/index.html}

\end{description}

\end{comment}

\bibliographystyle{acm}
\bibliography{other,my}

\end{document}

